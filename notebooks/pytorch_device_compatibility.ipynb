{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the `get_torch_device` Function from `utils.py`\n",
    "\n",
    "## Overview\n",
    "We have added a utility function, `get_torch_device`, in the `utils.py` script. This function automatically detects the best available device for running PyTorch computations, ensuring compatibility across different operating systems and hardware configurations.\n",
    "\n",
    "## **Rationale**\n",
    "Since our users work on different environments—MacBook Pro with M1/M2 chips, Macs without GPU acceleration, Windows machines, and Linux systems—it's important to have a robust and flexible device selection mechanism. This function ensures that:\n",
    "\n",
    "- On **macOS with M1/M2 chips**, PyTorch uses the **MPS backend** for GPU acceleration.\n",
    "- On **Windows and Linux machines with CUDA-enabled GPUs**, PyTorch selects **CUDA** for GPU acceleration.\n",
    "- On systems **without a GPU**, PyTorch defaults to **CPU** execution.\n",
    "\n",
    "This approach allows our PyTorch code to run seamlessly on any system without requiring manual configuration from users.\n",
    "\n",
    "---\n",
    "\n",
    "## **Function Implementation in `utils.py`**\n",
    "The following function has been implemented in `utils.py`:\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import platform\n",
    "\n",
    "def get_torch_device():\n",
    "    \"\"\"\n",
    "    Detects the best available PyTorch device based on the user's operating system and hardware.\n",
    "    \n",
    "    Supports:\n",
    "      - macOS with M1/M2 chip (MPS backend)\n",
    "      - macOS without GPU (CPU fallback)\n",
    "      - Windows/Linux with CUDA-enabled GPU\n",
    "      - Windows/Linux without GPU (CPU fallback)\n",
    "    \n",
    "    Returns:\n",
    "        torch.device: The best available device.\n",
    "    \"\"\"\n",
    "    system = platform.system()\n",
    "    \n",
    "    # Check for macOS with MPS support\n",
    "    if system == \"Darwin\":\n",
    "        if hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "            return torch.device(\"mps\")\n",
    "    \n",
    "    # Check for CUDA support on Windows/Linux\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    \n",
    "    # Default to CPU\n",
    "    return torch.device(\"cpu\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **How to Check That the Function Works**\n",
    "You can verify that the function correctly detects your available\n",
    "PyTorch device by running the following test script:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: mps\n",
      "Tensor is on device: mps:0\n"
     ]
    }
   ],
   "source": [
    "from surveyonadapters.utils import get_torch_device\n",
    "import torch\n",
    "\n",
    "# Get the best available device\n",
    "device = get_torch_device()\n",
    "print(f\"Running on device: {device}\")\n",
    "\n",
    "# Create a test tensor on the selected device\n",
    "x = torch.randn(10, 5).to(device)\n",
    "print(f\"Tensor is on device: {x.device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Expected Outputs**\n",
    "- **On a MacBook Pro with an M1/M2 chip (GPU enabled)**:\n",
    "  ```\n",
    "  Running on device: mps\n",
    "  Tensor is on device: mps:0\n",
    "  ```\n",
    "- **On a Windows/Linux machine with a CUDA-enabled GPU**:\n",
    "  ```\n",
    "  Running on device: cuda\n",
    "  Tensor is on device: cuda:0\n",
    "  ```\n",
    "- **On a system without a GPU (CPU fallback)**:\n",
    "  ```\n",
    "  Running on device: cpu\n",
    "  Tensor is on device: cpu\n",
    "  ```\n",
    "\n",
    "This function ensures our PyTorch code runs smoothly across different environments, requiring no manual configuration from users.\n",
    "\n",
    "---\n",
    "\n",
    "## **Conclusion**\n",
    "By incorporating `get_torch_device` into `utils.py`, we have streamlined PyTorch device selection for all users, making our code more portable and efficient. This allows us to focus on model development without worrying about hardware-specific configurations.\n",
    "\n",
    "For any issues or improvements, please update `utils.py` accordingly and notify the team.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "surveyonadapters-cH0-BN5P-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
